Female = weighted.mean(Female.x, Female.y, na.rm = T))
View(dm3)
dm2 == ds2
dm2 == ds
sum(!(dm2 == ds))
sum(!(dm2 == ds),na.rm = T)
dm <- read_table("https://www.prdh.umontreal.ca/BDLC/data/ont/Mx_1x1.txt", skip = 2, col_types = "ddddd")
dm2 <- read_table("https://www.prdh.umontreal.ca/BDLC/data/ont/Population.txt", skip = 2, col_types = "ddddd")
dm3 <- dm %>%
left_join(dm2, by = c("Year", "Age")) %>%
group_by(Year) %>%
summarise(Male = weighted.mean(Male.x, Male.y, na.rm = T),
Female = weighted.mean(Female.x, Female.y, na.rm = T))
dm1<- read_table("https://www.prdh.umontreal.ca/BDLC/data/ont/Mx_1x1.txt", skip = 2, col_types = "ddddd")
sum(!(dm1 == dm),na.rm = T)
View(dm3)
styler:::style_active_file()
sim <- function(z1,z2, n, t = 1:12) {
treatmenttime = stats::rnbinom(1,size = 1,prob = 0.5)+1
treatmenteffect = 0
lambda = ifelse(t < treatmenttime,z1 + z2* t, z1 + z2* t+treatmenteffect)
group <- matrix(rep(0, n * 12), ncol = 12)
for (i in 1:ncol(group)) {
group[, i] = rexp(n, rate = lambda[i])+rnorm(n)
}
return(cbind(group, z1, z2))
}
# Constant low Group
group1 <- sim(z1 = 2,
z2 = 0,
n = 3000)
# Increasing Group
group2 <- sim(z1 = 0.3,
z2 = -0.02,
n = 1000)
# Decreasing Group
group3 <- sim(z1 = 0.15,
z2 = 0.01,
n = 1000)
dart <- as.data.frame(cbind(1:5000, rbind(group1, group2, group3)))
dart[,2:13] <- round(dart[,2:13])
dart[,2:13] <- apply(dart[,2:13], c(1,2),function(x) min(x,10))
dart[,2:13] <- apply(dart[,2:13], c(1,2),function(x) max(x,0))
colnames(dart) <- c("id", 1:12, "cova", 'covb')
dart_long <- melt(data = dart,id.vars = c('id', 'cova', 'covb'))
dart_long$group <- c(rep('Group 1, n=3000',3000),rep('Group 2, n=1000',1000),rep('Group 3, n=1000',1000))
dart_long$variable <- as.numeric(dart_long$variable)
m1 <<- lcmm(value ~ variable,
subject = 'id',
data = dart_long,
link = 'thresholds')
conv= F
iter = 0
while(conv==F & iter <20){
m2 <- lcmm(value ~ variable,
mixture = ~ variable,
subject = 'id',
data = dart_long,
link = 'thresholds',
classmb = ~cova+covb,
ng = 2,
B = random(m1)
)
conv <- m2$conv==1
iter = iter +1
}
conv= F
iter = 0
while(conv==F & iter <20){
m3 <- lcmm(value ~ variable,
mixture = ~ variable,
subject = 'id',
data = dart_long,
link = 'thresholds',
classmb = ~cova+covb,
ng = 3,
B = random(m1)
)
conv <- m3$conv==1
iter = iter +1
}
c(m1$conv, m1$BIC, m2$conv, m2$BIC, m3$conv, m3$BIC
）
c(m1$conv, m1$BIC, m2$conv, m2$BIC, m3$conv, m3$BIC）
c(m1$conv, m1$BIC, m2$conv, m2$BIC, m3$conv, m3$BIC)
dart
dart[dart==10]
dart[,dart==10]
table(dart[.2])
table(dart[,2])
index <- which(dart[,i]==10)
i=2
index <- which(dart[,i]==10)
dart[i,index] <- 0
dart[i,index] <- rep(9,length(index))
dart[index,i] <- 9
which(dart[,i]==10)
dart[index,i] <- 9
View(dart)
table(dart$`1`)
for( i in 2:13){
index <- which(dart[,i]==10)
dart[index,i] <- 9
}
write.table(dart,quote = F,row.names = F,col.names = F,sep = "\t")
write.table(dart,quote = F,row.names = F,col.names = F,sep = "\t", file='test.dat')
getwd
getwd()
c(m1$conv, m1$BIC, m2$conv, m2$BIC, m3$conv, m3$BIC)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
library(tidyverse)
library(here)
# for bayes stuff
library(rstan)
library(bayesplot)
library(loo)
library(tidybayes)
ds <- read_rds("births_2017_sample.RDS")
head(ds)
library(tidyverse)
library(here)
# for bayes stuff
library(rstan)
library(bayesplot)
library(loo)
library(tidybayes)
ds <- read_rds("births_2017_sample.RDS")
head(ds)
ds <- ds %>%
rename(birthweight = dbwt, gest = combgest) %>%
mutate(preterm = ifelse(gest<32, "Y", "N")) %>%
filter(ilive=="Y",gest< 99, birthweight<9.999)
ds %>% ggplot(aes(x = gest, y = birthweight)) + geom_point() + geom_smooth(method = "lm")
ds %>% ggplot(aes(x = preterm, y = birthweight)) + geom_boxplot()
ds %>% ggplot(aes(x= birthweight, color = sex))+geom_histogram()
y <- c()
for(i in 1:1000){
beta0 <- rnorm(1, 0,1)
beta1 <- rnorm(1, 0,1)
sigma <- abs(rnorm(1, 0,1))
mu <- beta0 + beta1 * scale(log(ds$gest))
yi <- rnorm(length(mu), mean = mu, sd = sigma)
y <- c(y, yi)
}
hist(y, freq=F)
ds$log_weight <- log(ds$birthweight)
ds$log_gest_c <- (log(ds$gest) - mean(log(ds$gest)))/sd(log(ds$gest))
# put into a list
stan_data <- list(N = nrow(ds),
log_weight = ds$log_weight,
log_gest = ds$log_gest_c)
mod1 <- stan(data = stan_data,
file = "simple_weight.stan",
iter = 500,
seed = 243)
summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),]
mod1 <- stan(data = stan_data,
file = "simple_weight.stan",
iter = 500,
seed = 243)
summary(mod1)$summary[c("beta[1]", "beta[2]", "sigma"),]
# put into a list
ds$z <- ifelse(ds$preterm == "Y", 1, 0)
ds$z_gest <- ds$z * ds$log_gest_c
stan_data <- list(N = nrow(ds),
log_weight = ds$log_weight,
log_gest = ds$log_gest_c,
z = ds$z,
z_gest = ds$z_gest)
mod2 <- stan(data = stan_data,
file = "interaction_weight.stan",
iter = 500,
seed = 243)
summary(mod2)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]
load("mod2.Rda")
summary(mod2)$summary[c(paste0("beta[", 1:4, "]"), "sigma"),]
set.seed(1856)
y <- ds$log_weight
yrep1 <- extract(mod1)[["log_weight_rep"]]
yrep2 <- extract(mod2)[["log_weight_rep"]] # will need mod2 for later
samp100 <- sample(nrow(yrep1), 100)
ppc_dens_overlay(y, yrep1[samp100, ])  + ggtitle("distribution of observed versus predicted birthweights")
yrep2.sampled <- yrep2[sample(nrow(yrep2), 100),]
yrep2.sampled <- data.frame(rbind(yrep2.sampled, y))
yrep2.sampled$index <- 1:nrow(yrep2.sampled)
yrep2.sampled$type <- c(rep("rep",100), "y")
yrep2.sampled <- yrep2.sampled %>% gather(key = "key", value = "value", X1:X3842)
yrep2.sampled$type <- "rep"
yrep2.sampled %>% ggplot(aes(x=value, group=index, color = type)) + geom_density() + theme(legend.title=element_blank())
yrep2.sampled <- yrep2[sample(nrow(yrep2), 100),]
yrep2.sampled <- data.frame(rbind(yrep2.sampled, y))
yrep2.sampled$index <- 1:nrow(yrep2.sampled)
yrep2.sampled$type <- c(rep("rep",100), "y")
yrep2.sampled <- yrep2.sampled %>% gather(key = "key", value = "value", X1:X3842)
yrep2.sampled %>% ggplot(aes(x=value, group=index, color = type)) + geom_density() + theme(legend.title=element_blank())
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
?ppc_stat_grouped
quartz()
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
dev.off()
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = 'median')
ppc_stat_grouped(ds$log_weight, yrep1, group = ds$preterm, stat = function(x) sum(x < log(2.5)))
View(yrep1)
cutoff <- log(2.5)
cutoff <- log(2.5)
T <- sum(y < cutoff)/ length(y)
t.obs <- sum(y < cutoff)/ length(y)
1:nrow(yrep1)
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
set.seed(1856)
y <- ds$log_weight
yrep1 <- extract(mod1)[["log_weight_rep"]]
yrep2 <- extract(mod2)[["log_weight_rep"]] # will need mod2 for later
samp100 <- sample(nrow(yrep1), 100)
ppc_dens_overlay(y, yrep1[samp100, ])  + ggtitle("distribution of observed versus predicted birthweights")
mod1 <- stan(data = stan_data,
file = "simple_weight.stan",
iter = 500,
seed = 243)
# put into a list
ds$z <- ifelse(ds$preterm == "Y", 1, 0)
ds$z_gest <- ds$z * ds$log_gest_c
stan_data <- list(N = nrow(ds),
log_weight = ds$log_weight,
log_gest = ds$log_gest_c,
z = ds$z,
z_gest = ds$z_gest)
mod2.own <- stan(data = stan_data,
file = "interaction_weight.stan",
iter = 500,
seed = 243)
set.seed(1856)
y <- ds$log_weight
yrep1 <- extract(mod1)[["log_weight_rep"]]
yrep2 <- extract(mod2.own)[["log_weight_rep"]] # will need mod2 for later
samp100 <- sample(nrow(yrep1), 100)
ppc_dens_overlay(y, yrep1[samp100, ])  + ggtitle("distribution of observed versus predicted birthweights")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1)
abline(v = t.obs)
hist(t.m1)
abline(v = t.obs)
hist(t.m1, xlim = c(0.05, 0.15))
abline(v = t.obs)
hist(t.m1, xlim = c(0.05, 0.15))
abline(v = t.obs)
hist(t.m2)
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15))
abline(v = t.obs)
hist(t.m2, xlim = c(0.05, 0.15))
abline(v = t.obs)
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, color= "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, color = 'red)
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, color= "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, color = 'red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, color= "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, color = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, color = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
legend(0.13, 50, legend = "observed T", col = "red")
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
legend(0.13, 50, legend = "observed T", col = "red", lty=1)
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
legend(0.12, 50, legend = "observed T", col = "red", lty=1)
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
legend(0.125, 50, legend = "observed T", col = "red", lty=1)
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1")
abline(v = t.obs, col= "red")
legend(0.125, 50, legend = "observed T", col = "red", lty=1)
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2")
abline(v = t.obs, col = "red")
legend(0.125, 50, legend = "observed T", col = "red", lty=1)
cutoff <- log(2.5)
t.obs <- sum(y < cutoff)/ length(y)
t.m1 <- c()
t.m2 <- c()
for (i in 1:1000) {
t.m1 <- c(t.m1, sum(yrep1[i,]<cutoff)/length(yrep1[i,]))
t.m2 <- c(t.m2, sum(yrep2[i,]<cutoff)/length(yrep2[i,]))
}
hist(t.m1, xlim = c(0.05, 0.15), main = "Model 1", xlab = "prop < log(2.5) in y rep")
abline(v = t.obs, col= "red")
legend(0.125, 50, legend = "observed T", col = "red", lty=1)
hist(t.m2, xlim = c(0.05, 0.15), main = "Model 2", xlab = "prop < log(2.5) in y rep")
abline(v = t.obs, col = "red")
legend(0.125, 50, legend = "observed T", col = "red", lty=1)
loglik1 <- extract(mod1)[["log_lik"]]
loglik2 <- extract(mod2)[["log_lik"]]
?sd
pt(0.975)
pt(0.975, df =10)
pt(0.975, df =9)
pt(0.995, df =9)
pt(1-0.99/2, df =9)
qt(1-0.99/2, df =9)
qt(1-0.99/2, df =9)
qt(1-0.99/2, df =10)
qt(1-(0.99/2), df =10)
qt(0.995, df =10)
qt(0.995, df =9)
qt(0.975, df =9)
library(ranger)
library(readr)
library(dplyr)
library(data.table)
library(tidyr)
setwd("/Users/jianhuigao/OneDrive - University of Toronto/EHR_research/PHD_thesis/SyntheticSurrogateAnalysis/Data/")
# load Dataset
pheno <- fread("Phenotype.tab")
waist <- fread("waist.tab")
weight <- read_table2("Weight.txt")
pheno <- cbind(pheno, weight[,2], waist[,2])
# Only keep measurement from initial visit
field <- "50" # weight
fieldlist <- c(field, "22001", "21022", "21002", "48") # height, sex, age, weight, waist
pheno <- pheno %>% select(c("f.eid", paste0("f.", fieldlist, ".0.0")))
colnames(pheno) <- c("id", "height", "sex", "age", "weight", "waist")
# Read inviduals used for association data
ID <- read_table("id.txt", col_names = F)[, 1]
colnames(ID) <- c("id")
pheno <- inner_join(pheno, ID) %>% drop_na()
save(pheno, file = "height_prediction.RData")
library(data.table)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(scattermore)
library(fastman)
# read summary statistics from nealab
nealab <- fread("50_irnt.gwas.imputed_v3.both_sexes.tsv")
# filter out maf > 0,05
nealab <- nealab %>%
filter(minor_allele > 0.05) %>%
select(c("variant","minor_allele","beta", "pval"))
# seperate variant into chr, BP, allele1, allele2
split <- str_split_fixed(nealab$variant, ":", 4)
nealab$CHR <- as.numeric(split[, 1])
nealab$BP <- as.numeric(split[, 2])
nealab$a1 <- split[, 3]
nealab$a2 <- split[, 4]
nealab <- nealab %>%
filter(a1 %in% c("A", "T", "C", "G")) %>% # exclude all In-Del variants
filter(a2 %in% c("A", "T", "C", "G")) %>% # exclude all In-Del variants
rename(P = pval)
# If minor allele != alt2, then the sign of beta needs to be changed. As plink forces alt2 to be minor allele.
nealab <- nealab %>%
mutate(flip = ifelse(a2 == minor_allele, FALSE, TRUE))%>%
mutate(beta = ifelse(flip, -beta, beta)) %>%
select(c("CHR", "BP", "beta", "P")) %>%
filter(P > 0) %>%
drop_na()
save(nealab, file = "height_nlab.RData")
# Load Data
setwd("/Users/jianhuigao/OneDrive - University of Toronto/EHR_research/PHD_thesis/SyntheticSurrogateAnalysis/Data/")
gwas <- fread("plink2.PHENO1.glm.linear") %>% filter(TEST == "ADD") # only need genetic coef
gwas <- gwas %>% rename(CHR = `#CHROM`, BP = POS) %>% filter(P > 0)
gwas$P <- as.numeric(gwas$P)
load("height_nlab.Rdata")
# Manhattan plots
setwd("/Users/jianhuigao/OneDrive - University of Toronto/EHR_research/PHD_thesis/SyntheticSurrogateAnalysis/Result/")
png("height_manhattan.png", width = 10, height = 6, units = "in", res = 300)
fastman(gwas, suggest_line = FALSE) # Fast Manhattan plot
dev.off()
png("height_manhattan_nlab.png", width = 10, height = 6, units = "in", res = 300)
fastman(nealab, suggest_line = FALSE, main = "Nealab Result Manhattan plot") # Fast manhattan plot
dev.off()
# Plot p-value contrast
combined <- inner_join(gwas, nealab, by = c("CHR", "BP")) # only include snps in both results
png("pval_scatter.png")
ggplot(data = combined, aes(x = -log10(P.x), y = -log10(P.y))) +
geom_scattermore() + # fast scatter plot from scattermore
geom_abline(intercept = 0, color = "red") + # add 45 degree line
xlab("pval") +
ylab("pval from nealab")
dev.off()
# Plot effect size contrast
png("beta_scatter.png")
ggplot(data = combined, aes(x = BETA, y = beta)) +
geom_scattermore() + # fast scatter plot from scattermore
geom_abline(intercept = 0, color = "red", linetype =2) + # add 45 degree line
xlab("Effect Size") +
ylab("Effect Size from Nealab")
dev.off()
